# README

This is a `Python` script for web scraping using the Scrapy framework. It defines a spider named "Data" that is used to scrape pricing information for products from a retail website.

The spider starts by prompting the user to enter a name for the output file. It then defines a dictionary called "cmp" that will be used to store the scraped data. The spider then defines a method called "closed" that will be called when the spider is finished. The "closed" method creates a Pandas dataframe from the data in the "cmp" dictionary and writes it to an Excel file with the name entered by the user.

The spider then defines a method called "start_requests" that is used to generate a list of URLs to scrape. The URLs are generated by combining a list of product IDs with a list of zip codes, and then using a formatted string to create the final URL. The spider then sends a request to each URL using the Scrapy framework.

The spider defines a method called "parse" that is used to parse the response from each URL. The method extracts the store ID from the JSON response and uses it to send a second request to an API endpoint. The method then passes the response to a method called "parse_detail".

The "parse_detail" method extracts the product name and pricing information from the JSON response and stores it in the "cmp" dictionary.

Finally, the spider logs the number of products that have been scraped using the Scrapy framework.

Overall, this script demonstrates how to use the Scrapy framework to scrape data from a retail website and store it in a Pandas dataframe.
